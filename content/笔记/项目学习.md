title: 项目学习
Date: 2023-5-10 10:00:00
Category: 笔记
tags: Alexander

# 项目学习

##  深度学习概念简介

###  机器学习主要内容

####  监督学习

我们拥有具体的数据和预测目标（标签），需要从数据出发构造具体的模型预测目标，当然模型预测越准确越好，其代表的主要任务包括回归（预测连续的值，如根据历史的气温预测未来的气温）和分类（预测离散的值，根据图片预测图片描述的具体物体的类型）

####  无监督学习

我们只有数据，没有预测目标需要构造具体的模型来找出数据的具体规律。其代表的主要内容包括聚类（找出相似多组数据，并把它们归类）。

#### 卷积神经网络

```
​```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # 定义卷积层
        self.conv1 = nn.Conv2d(1, 6, 5) # 输入通道数为1，输出通道数为6，卷积核大小为5x5
        # 定义池化层
        self.pool = nn.MaxPool2d(2, 2) # 池化核大小为2x2，步长为2
        # 定义卷积层
        self.conv2 = nn.Conv2d(6, 16, 5) # 输入通道数为6，输出通道数为16，卷积核大小为5x5
        # 定义全连接层
        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 输入大小为16x5x5，输出大小为120
        self.fc2 = nn.Linear(120, 84) # 输入大小为120，输出大小为84
        self.fc3 = nn.Linear(84, 10) # 输入大小为84，输出大小为10

    def forward(self, x):
        # 通过卷积层1，使用ReLU激活函数，然后进行池化
        x = self.pool(F.relu(self.conv1(x)))
        # 通过卷积层2，使用ReLU激活函数，然后进行池化
        x = self.pool(F.relu(self.conv2(x)))
        # 将张量展平
        x = x.view(-1, 16 * 5 * 5)
        # 通过全连接层1，使用ReLU激活函数
        x = F.relu(self.fc1(x))
        # 通过全连接层2，使用ReLU激活函数
        x = F.relu(self.fc2(x))
        # 通过全连接层3，不使用激活函数
        x = self.fc3(x)
        return x
​```
```

> 这个卷积神经网络包括两个卷积层和三个全连接层。在前向传播过程中，输入张量通过卷积层1和ReLU激活函数，然后进行池化。接着，输出张量通过卷积层2和ReLU激活函数，然后进行池化。最后，输出张量被展平并通过三个全连接层进行处理。在每个全连接层中，输出张量都通过ReLU激活函数，除了最后一个全连接层，它没有激活函数。

#### 主函数

```
​```python
import torch
import torchvision
import torchvision.transforms as transforms
import torch.optim as optim
import torch.nn as nn
from net import Net

# 定义数据预处理方式
transform = transforms.Compose(
    [transforms.ToTensor(), # 将图像转换为张量
     transforms.Normalize((0.5,), (0.5,))]) # 标准化

# 加载训练集
trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,
                                          shuffle=True, num_workers=2)

# 加载测试集
testset = torchvision.datasets.MNIST(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64,
                                         shuffle=False, num_workers=2)

# 定义模型、损失函数和优化器
net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

# 训练模型
for epoch in range(10): # 进行10轮训练
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # 获取输入数据
        inputs, labels = data

        # 将梯度清零
        optimizer.zero_grad()

        # 前向传播、计算损失、反向传播、更新参数
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # 打印统计信息
        running_loss += loss.item()
        if i % 200 == 199:    # 每200个batch打印一次
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 200))
            running_loss = 0.0

print('Finished Training')

# 测试模型
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        # 获取输入数据
        images, labels = data

        # 前向传播、计算损失、反向传播、更新参数
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))
```

> 这个卷积神经网络是用于图像分类任务的。它包含两个卷积层和三个全连接层，可以对输入的图像进行特征提取和分类。具体来说，它将输入的图像通过卷积层和池化层进行特征提取，然后通过全连接层进行分类，最终输出图像的类别。

## Webots学习

#### wb_robot_init()

初始化机器人控制器

#### wb_robot_step()

执行一步仿真

#### wb_robot_get_time()

获取当前仿真时间

#### wb_supervisor_node_get_type()

获取节点类型

> 在Webots中，节点是指场景中的任何对象，包括机器人、传感器、环境等。节点可以是可视化的，也可以是不可视化的。节点可以包含属性、方法和事件，可以通过编程来控制它们的行为。 节点在Webots中的作用非常重要，因为它们是构建机器人模拟场景的基本单元。通过创建和配置节点，用户可以构建复杂的机器人模型、添加传感器和执行器、设置环境参数等。节点还可以与其他节点进行交互，例如机器人可以通过传感器节点获取环境信息，然后根据这些信息来执行动作。 总之，节点是Webots中的基本构建块，它们的作用非常重要，可以帮助用户构建复杂的机器人模拟场景。

#### wb_supervisor_field_get_sf_vec3f()

>wb_supervisor_field_get_sf_vec3f()用于获取场景中某个节点的SFVec3f类型的字段值。具体来说，SFVec3f是Webots中的一种数据类型，表示一个三维向量，包含三个浮点数分别表示向量在x、y、z三个方向上的分量。wb_supervisor_field_get_sf_vec3f()函数可以用于获取场景中某个节点的SFVec3f类型的字段值，比如获取机器人的位置、速度、朝向等信息。这个函数的使用可以帮助开发者在Webots中获取机器人的状态信息，从而进行控制、规划等操作。

#### wb_supervisor_field_get_sf_rotation()

>wb_supervisor_field_get_sf_rotation()，用于获取场景中某个节点的旋转角度。具体来说，它可以用于获取场景中某个节点的四元数表示的旋转角度，即节点绕x、y、z轴旋转的角度。这个函数可以帮助用户在编写控制机器人的程序时，获取机器人当前的朝向，从而进行相应的控制。例如，如果用户想让机器人向前移动，就需要知道机器人当前的朝向，然后根据朝向来计算机器的运动方向。wb_supervisor_field_get_sf_rotation()函数就可以帮助用户获取机器人的朝向信息，从而实现这个功能。

#### wb_robot_get_device()

`camera = wb_robot_get_device("camera");`得到设备的摄像头

>`wb_robot_get_device`是Webots中的一个函数，用于获取设备对象。在Webots中，设备是指机器人的各种传感器和执行器，如摄像头、激光雷达、电机等。wb_robot_get_device函数可以通过设备名称获取设备对象，从而可以对设备进行控制和读取数据。例如，可以使用以下代码获取名为"camera"的摄像头设备对象： ```c WbDeviceTag camera = wb_robot_get_device("camera"); ``` 获取设备对象后，可以使用其他函数对设备进行操作，例如读取摄像头图像数据、控制电机转动等。

#### wb_motor

> wb_motor是一个Python库，用于控制树莓派上的GPIO引脚，从而控制电机的转动。它可以与各种类型的电机一起使用，例如直流电机、步进电机等。wb_motor库提供了简单易用的API，使得用户可以轻松地编写控制电机的程序。

#### wb_motor_set_position()

>wb_motor_set_position()用于设置电机的目标位置。它的作用是控制电机转动到指定的位置，可以用于控制机器人的运动。 在Webots中，电机可以通过设置目标位置来控制它的转动。wb_motor_set_position()函数可以将电机转动到指定的位置，它的参数是一个double类型的值，表示电机的目标位置。 
>
>例如，如果想让机器人的左轮电机转动到90度的位置，可以使用以下代码：

```
WbDeviceTag left_motor = wb_robot_get_device("left wheel motor");
wb_motor_set_position(left_motor, 90.0);
```

> 这样，左轮电机就会转动到90度的位置。

#### wb_motor_set_velocity()

> wb_motor_set_velocity(left_motor, 0.0);
>
> 这行代码是用来设置左侧电机的速度为0，即停止左侧电机的运动。wb_motor_set_velocity()是Webots机器人仿真软件中的一个函数，用于设置电机的速度。在这里，left_motor是一个电机设备的指针，0.0表示速度为0。这行代码的作用是停止左侧电机的运动，可能是为了控制机器人的运动或者进行某些特定的操作。

#### wb_robot_step()

> wb_robot_step(time_step)用于控制仿真器的时间步长。在仿真器中，时间步长是指仿真器在每一次循环中更新的时间量。wb_robot_step(time_step)函数的作用是让仿真器在每个时间步长中执行一次循环，以便模拟物理世界的运动和交互。time_step参数表示每个时间步长的时间量，以毫秒为单位。例如，如果time_step=10，则仿真器将每10毫秒更新一次。这个函数通常在控制机器人或其他物体的运动时使用。

#### wb_camera_get_image()

> wb_camera_get_image(camera)是一个函数，用于从相机中获取图像。它需要一个相机对象作为参数，并返回一个图像对象。这个函数可以用于从相机中读取实时视频流或者静态图像。在使用这个函数之前，需要先初始化相机对象并打开相机。

#### wb_robot_cleanup()

> wb_robot_cleanup()是Webots API中的一个函数，用于清理Webots机器人控制器程序的资源。当机器人控制器程序执行完毕或需要重置时，应该调用wb_robot_cleanup()函数来释放所有已分配的资源，包括设备、传感器、执行器等。这可以确保程序在下一次运行时不会出现任何问题，并且可以避免内存泄漏等问题。

#### wb_camera_save_image()

> wb_camera_save_image是一个函数，用于将相机捕获的图像保存到指定的文件中。这个函数通常在需要保存相机捕获的图像时使用，例如在图像处理或计算机视觉应用中。函数的参数包括相机对象、保存图像的文件名、保存图像的格式等。`wb_camera_save_image(camera, filepath, 100)`中的100是指图像质量，取值范围为0-100，表示保存图像的压缩质量。值越大，图像质量越高，文件大小也越大。一般情况下，建议将图像质量设置为80-90之间。

#### wbu_system_getenv()

> wbu_system_getenv是一个函数，用于获取指定环境变量的值。在操作系统中，环境变量是一些可以在系统中存储和访问的值，它们通常用于配置系统和应用程序的行为。wbu_system_getenv函数可以帮助应用程序获取环境变量的值，从而根据环境变量的值来决定应用程序的行为。例如，可以使用该函数来获取系统的语言设置，以便应用程序可以根据语言设置来显示正确的界面语言。

#### wb_camera_image_get()

> wb_camera_image_get是一个函数，用于获取相机的图像数据。它可以从相机中获取当前帧的图像数据，并将其存储在指定的缓冲区中。这个函数通常用于相机应用程序中，以便将相机捕获的图像数据传递给其他处理模块，如图像处理算法、计算机视觉算法等。

#### wb_camera_image_get_red()

> wb_camera_image_get_red是一个函数，用于获取图像中红色通道的像素值。它通常用于图像处理和计算机视觉应用中，例如在图像分割、目标检测和识别等任务中，需要提取图像中的红色物体或区域。此函数可以从相机或图像文件中读取图像，并返回一个包含红色通道像素值的数组。

#### wb_robot_get_basic_time_step()

> wb_robot_get_basic_time_step是Webots中的一个函数，用于获取仿真时间步长。仿真时间步长是指仿真器在每个仿真步骤中前进的时间量。该函数通常用于控制机器人的运动和行为，以便在每个时间步长内更新机器人的状态和执行相应的操作。例如，可以使用该函数来控制机器人的速度、方向和位置，以便在仿真中模拟真实世界中的行为。

## Webots使用python的API

```
​```python
# 导入Webots Python API
from controller import Robot, Camera

# 创建机器人实例
robot = Robot()

# 获取RGBD相机实例
camera = robot.getDevice('rgbd_camera')

# 设置相机参数
camera.enable(10)  # 设置帧率为10帧/秒
camera.enableDepth(True)  # 启用深度图像

# 获取RGBD数据
while robot.step(1) != -1:
    # 获取RGB图像
    rgb_image = camera.getImage()

    # 获取深度图像
    depth_image = camera.getRangeImage()

    # 处理RGBD数据
    # ...

​```
```

> 在上面的示例中，我们首先导入Webots Python API。然后，我们创建一个机器人实例，以便我们可以访问Webots中的设备。接下来，我们获取RGBD相机实例，并设置相机参数。最后，我们在一个循环中获取RGBD数据，并对其进行处理。



